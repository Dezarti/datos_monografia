{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocesamiento de imágenes**\n",
        "\n",
        "El presente notebook tiene como objetivo el preprocesar las imágenes de ultrasonido antes de incorporarlas en el entrenamiento y evaluación de la inteligencia artificial."
      ],
      "metadata": {
        "id": "D9HHTlKFB9EA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resumen\n",
        "\n",
        "Como ya se comentó en el archivo README.md, las imágenes de ultrasonido son en su totalidad capturas de pantallas del software donde se visualizan. Generalmente estas capturas de pantalla las generan los radiólogos para poder hacer apuntes o marcas que ayuden al diagnóstico por parte del médico. Se evaluaron diferentes aproximaciones, como el uso crudo de las imágenes o el recorte automatizado de estas.\n",
        "Para la primera aproximación si bien se podría hacer un uso completo de todas las imágenes, la información del software que se cuela en la captura de pantalla podría ser irrelevante en el entrenamiento y de momento no se tiene claro que tanto lo podría alterar, por lo cual momentáneamente se descarta, aunque con base en los resultados futuros de entrenamiento quizá se podría retomar.\n",
        "Para la segunda aproximación, a través de OpenCV (cv2) se detectaron los bordes de la imagen para generar el recorte. A veces se logró un buen resultado, pero en otras ocasiones fueron no fueron los deseados y no mejoraron por más que se ajustaran los parámetros. Después de un leve análisis se logró determinar que se podrían filtrar las imágenes funcionales a partir de su peso, siendo 350 kb el límite para considerarla funcional.\n",
        "\n",
        "Con el procedimiento anterior se pasó de 2097 imágenes a poco más de 600, pero estas últimas nuevamente fueron filtradas, ya esta vez manualmente para asegurar su funcionalidad. A la par se revisaron parte de los nombres manualmente puesto que la clasificación que muchas imágenes tenían en el nombre estaba incorrecta.\n"
      ],
      "metadata": {
        "id": "pPrVxIhUI3Yl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metodología"
      ],
      "metadata": {
        "id": "003BRl_FRL-P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recorte de imágenes\n",
        "\n",
        "Son 2097 imágenes, lo que indica que el recorte manual, aunque posible, es una tarea muy demandante.\n",
        "\n",
        "A partir de reconocimientos de bordes se intentó recortar cada una de las imágenes. Es importante destacar que antes de antes de esta metodología se intentaron otras haciendo uso de algoritmos como Canny o librerías como scikit-image, pero fue con OpenCV que se obtuvieron los mejores resultados."
      ],
      "metadata": {
        "id": "pn8dfqqDl9Sv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos librerías necesarias\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import io, filters, measure\n",
        "import os\n",
        "\n",
        "\n",
        "def cortar_imagen(image_path, output_path):\n",
        "    \"\"\"\n",
        "    Permite recortar una imágen de ultrasónido dentro de una captura\n",
        "    de pantalla según los bordes de esta\n",
        "\n",
        "    Args:\n",
        "        image_path (str): ruta de la captura de pantalla\n",
        "        output_path (str): ruta de destino de la imágen recortada\n",
        "    \"\"\"\n",
        "\n",
        "    # Leer la imagen del camino especificado decartando el canal alfa\n",
        "    imagen = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)[:,:,:3]\n",
        "\n",
        "    # Convertir la imagen a escala de grises\n",
        "    imagen_gris = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Umbralizar la imagen para obtener una imagen binaria\n",
        "    _, imagen_binaria = cv2.threshold(imagen_gris, 0, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Encontrar contornos en la imagen binaria\n",
        "    contornos, _ = cv2.findContours(imagen_binaria, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Encontrar el contorno más grande, basado en el área\n",
        "    contorno_mas_grande = max(contornos, key=cv2.contourArea)\n",
        "\n",
        "    # Obtener el rectángulo delimitador del contorno más grande\n",
        "    x, y, ancho, alto = cv2.boundingRect(contorno_mas_grande)\n",
        "\n",
        "    # Recortar la imagen al rectángulo delimitador\n",
        "    imagen_recortada = imagen[y:y+alto, x:x+ancho]\n",
        "\n",
        "    # Guardar la imagen recortada en el camino de salida especificado\n",
        "    io.imsave(output_path, imagen_recortada)\n",
        "\n",
        "# Ruta de las carpetas de las imágenes originales y destino de los\n",
        "# recortes. Es importante que las carpetas contengan solo las imágenes\n",
        "# que se van a procesar\n",
        "input_folder = '/content/drive/MyDrive/Materias/Monografía/Tercera entrega - 03 Noviembre/Dataset original/US_Pictures'\n",
        "output_folder = '/content/drive/MyDrive/Materias/Monografía/Tercera entrega - 03 Noviembre/images_test_4'\n",
        "\n",
        "# Procesar cada imagen en la carpeta\n",
        "for filename in os.listdir(input_folder):\n",
        "    try:\n",
        "        # Verificar si el archivo es una imagen basado en su extensión\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif')):\n",
        "            # Construir la ruta completa de la imagen de entrada y de salida\n",
        "            input_path = os.path.join(input_folder, filename)\n",
        "            base_name = os.path.splitext(filename)[0]\n",
        "            output_path = os.path.join(output_folder, base_name)\n",
        "            # Llamar a la función para cortar y guardar la imagen\n",
        "            cortar_imagen(input_path, output_path)\n",
        "    except Exception as e:\n",
        "        # Si hay un error, imprimirlo y continuar con la siguiente imagen\n",
        "        print(f\"No se pudo procesar el archivo: {filename}: {e}\")"
      ],
      "metadata": {
        "id": "8WIn23IDQm4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filtrado\n",
        "Si bien se recortaron todas las imágenes, muchas de estas no cumplieron con los resultados esperados, llegando a ser cuadros negros o demasiados pequeños para llevar a cabo un análisis decente.\n",
        "\n",
        "Se analizaron brevemente los resultados y se llegó a la conclusión de que generalmente si el peso de la imagen estaba por debajo de los 350 Kb significaba que esta NO serviría para el entrenamiento de la IA.\n",
        "\n",
        "Antes de establecer el límite de 350 kb, se hizo un conteo proponiendo varios límites de peso entre el rango de 250 - 500 kb con el fin de no descartar excesivamente imágenes o quedar con muchas de poca calidad.\n"
      ],
      "metadata": {
        "id": "nx92rGfaRPcN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conteo"
      ],
      "metadata": {
        "id": "RkfKhGJ3SqGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Ruta a la carpeta donde están los archivos\n",
        "folder_path = '/content/drive/MyDrive/Materias/Monografía/Tercera entrega - 03 Noviembre/images_test_4'\n",
        "\n",
        "# Tamaño en kilobytes\n",
        "size_threshold = 350 * 1024  # 300 KB en bytes\n",
        "\n",
        "# Contador para los archivos mayores a 300 KB\n",
        "count = 0\n",
        "\n",
        "# Listar todos los archivos en la carpeta\n",
        "for filename in os.listdir(folder_path):\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "    # Asegurarse de que es un archivo y no una carpeta/subcarpeta\n",
        "    if os.path.isfile(file_path):\n",
        "        # Obtener el tamaño del archivo\n",
        "        file_size = os.path.getsize(file_path)\n",
        "        # Comparar con el umbral\n",
        "        if file_size > size_threshold:\n",
        "            count += 1\n",
        "\n",
        "print(f\"Hay {count} archivos mayores a 300 KB.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsAQaLwqdx2o",
        "outputId": "650bde62-4f72-43ce-e2a7-4311c80ae97e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hay 694 archivos mayores a 300 KB.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selección\n",
        "Sabemos que hay al menos 694 imágenes que son más pesadas de 350 kb. Estas se copian en una nueva carpeta, se descargan y se revisan manualmente. La razón por la cual se optó por esta metodología fue por el tiempo del que se dispone, pues si bien parece una ardua labor, no se encontró ninguna otra forma en la cual extraer las imágenes y verificar automáticamente que estas estuvieran correctamente recortadas. Los autores reconocen que lo anterior no implica que sea imposible desarrollar una herramienta para tal labor o que esta no exista, pero no pudieron encontrarla e implementarla en los tiempos del presente trabajo.\n",
        "\n",
        "Finalmente, si bien se tiene la copia de las imágenes en drive, es mucho más rápido procesarlas localmente, de allí el motivo de su descarga."
      ],
      "metadata": {
        "id": "WGGlDFFZe27f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import io, filters, measure\n",
        "import os\n",
        "\n",
        "# Ruta a la carpeta donde están los archivos originales\n",
        "source_folder = '/content/drive/MyDrive/Materias/Monografía/Tercera entrega - 03 Noviembre/images_test_4'\n",
        "\n",
        "# Ruta a la carpeta donde quieres copiar los archivos\n",
        "destination_folder = '/content/drive/MyDrive/Materias/Monografía/Tercera entrega - 03 Noviembre/images_test_5'\n",
        "\n",
        "# Tamaño en kilobytes\n",
        "size_threshold = 350 * 1024  # 300 KB en bytes\n",
        "\n",
        "# Contador para los archivos mayores a 300 KB\n",
        "count = 0\n",
        "\n",
        "# Listar todos los archivos en la carpeta\n",
        "for filename in os.listdir(source_folder):\n",
        "    source_path = os.path.join(source_folder, filename)\n",
        "    # Asegurarse de que es un archivo y no una carpeta/subcarpeta\n",
        "    if os.path.isfile(source_path):\n",
        "        # Obtener el tamaño del archivo\n",
        "        file_size = os.path.getsize(source_path)\n",
        "        # Comparar con el umbral\n",
        "        if file_size > size_threshold:\n",
        "            # Copiar el archivo a la carpeta de destino\n",
        "            destination_path = os.path.join(destination_folder, filename)\n",
        "            shutil.copy2(source_path, destination_path)\n",
        "            count += 1\n",
        "\n",
        "print(f\"Se copiaron {count} archivos mayores a 350 KB a {destination_folder}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5qHwyeAfIG2",
        "outputId": "0ecaf6ff-2b5a-4ee1-ae3e-7ae8170d59cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se copiaron 694 archivos mayores a 350 KB a /content/drive/MyDrive/Materias/Monografía/Tercera entrega - 03 Noviembre/images_test_5.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Procesamiento\n",
        "\n",
        "De aquí en adelante lo que procura es generar una base de datos con las imágenes la cual pueda ser usada para el entrenamiento del modelo a desarrollar.\n",
        "\n",
        "Este preprocesamiento de imágenes debe ir orientado al modelo que se piensa desarrollar y para ello es importante recordar que la propuesta de este trabajo es el uso de redes neuronales convolucionales,, pero cuando se crea una red neuronal nueva todos sus parámetros inician de manera totalmente aleatoria y mediante el entrenamiento se ajustan gradualmente, el problema radica en que en este caso se cuenta únicamente con cientos de datos (580) lo que dificulta este proceso y aumentar el riesgo de caer en sobreajuste.\n",
        "\n",
        "Por lo anterior se buscará hacer un proceso de \"transferencia de aprendizaje\" es decir, tomar un modelo que sea bueno reconociendo imágenes de cualquier tipo y entrenarlo sobre nuestro set. Se pretende usar [MobileNetV2](https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/feature_vector/5) donde se descartarían todas las salidas existentes del modelo (1001 clasificaciones), es decir, la útima capa, para remplazarla por otra con 3 clasificaciones ('sin apendice', 'apendicitis', 'no_apendicitis') y se entrenarían solo las últimas capas del modelo (sin tocar las otras), posteriormente se podrían entrenar todas las capas, pero con una tasa de aprendizaje muy baja. En este trabajo no se profundizará más sobre esa metodología, pero se deseaba que el lector comprendiese el camino a tomar."
      ],
      "metadata": {
        "id": "Q1DxMmalyvYV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ordenar imágenes.\n",
        "\n",
        "Para la generación del modelo, se deben tener organizadas las imágenes y si bien algunas ya se organizaron manualmente, no fueron todas las categorias.\n",
        "\n",
        "Se tomará la info del dataset estructurado que venía con las imágenes para saber si los grupos están bien clasificados, para ello se usarán los número de identificación US"
      ],
      "metadata": {
        "id": "U15SptMj9Yw5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Datos estructurados"
      ],
      "metadata": {
        "id": "ZYS4CjPCA_bd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ruta del archivo\n",
        "file_path = 'https://raw.githubusercontent.com/Dezarti/datos_monografia/main/structured_data/app_data.xlsx'\n",
        "\n",
        "# Cargar la primera hoja del archivo Excel en un DataFrame\n",
        "df = pd.read_excel(file_path, sheet_name=0)\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame\n",
        "#df.head()\n",
        "\n",
        "# Columnas seleccionadas\n",
        "seleccion = ['Appendix_on_US', 'US_Number', 'Diagnosis']\n",
        "\n",
        "# Especificar las filas (todas) y columnas (seleccion) que se copiaran\n",
        "df_filtered = df.loc[:, seleccion]\n",
        "\n",
        "df_filtered # Dataframe"
      ],
      "metadata": {
        "id": "LGutKi2vbjb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "c4a42620-9568-404b-90a3-b65f1620ff98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Appendix_on_US  US_Number        Diagnosis\n",
              "0              yes      882.0     appendicitis\n",
              "1               no      883.0  no appendicitis\n",
              "2               no      884.0  no appendicitis\n",
              "3               no      886.0  no appendicitis\n",
              "4              yes      887.0     appendicitis\n",
              "..             ...        ...              ...\n",
              "777            yes      126.0     appendicitis\n",
              "778             no        NaN     appendicitis\n",
              "779             no      127.0     appendicitis\n",
              "780            yes      128.0     appendicitis\n",
              "781            yes      129.0     appendicitis\n",
              "\n",
              "[782 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17a31aba-1e96-4406-b64b-0420d7187f3e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Appendix_on_US</th>\n",
              "      <th>US_Number</th>\n",
              "      <th>Diagnosis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>yes</td>\n",
              "      <td>882.0</td>\n",
              "      <td>appendicitis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>no</td>\n",
              "      <td>883.0</td>\n",
              "      <td>no appendicitis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>no</td>\n",
              "      <td>884.0</td>\n",
              "      <td>no appendicitis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>no</td>\n",
              "      <td>886.0</td>\n",
              "      <td>no appendicitis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>yes</td>\n",
              "      <td>887.0</td>\n",
              "      <td>appendicitis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>777</th>\n",
              "      <td>yes</td>\n",
              "      <td>126.0</td>\n",
              "      <td>appendicitis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>778</th>\n",
              "      <td>no</td>\n",
              "      <td>NaN</td>\n",
              "      <td>appendicitis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>779</th>\n",
              "      <td>no</td>\n",
              "      <td>127.0</td>\n",
              "      <td>appendicitis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>780</th>\n",
              "      <td>yes</td>\n",
              "      <td>128.0</td>\n",
              "      <td>appendicitis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>781</th>\n",
              "      <td>yes</td>\n",
              "      <td>129.0</td>\n",
              "      <td>appendicitis</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>782 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17a31aba-1e96-4406-b64b-0420d7187f3e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-17a31aba-1e96-4406-b64b-0420d7187f3e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-17a31aba-1e96-4406-b64b-0420d7187f3e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f584a082-870a-4943-adc5-0136b28ecd52\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f584a082-870a-4943-adc5-0136b28ecd52')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f584a082-870a-4943-adc5-0136b28ecd52 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Revisión de valores únicos\n",
        "\n",
        "Será útil para entender el dataset y no cometer errores al filtrar más adelante."
      ],
      "metadata": {
        "id": "bLHE6ikAKTMz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mover imágenes de carpeta\n",
        "\n",
        "Se extraen los numeros de las imágenes, se buscan en el dataset df_filtered, de allí se elige a qué carpeta debe ir con base en la información que se encuentre."
      ],
      "metadata": {
        "id": "TZeqecqwKcGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os # Para navegar por las carpetas de colab\n",
        "import re # Para trabajar con expresiones regulares\n",
        "import shutil # Para cambiar los archivos de ubicación\n",
        "import traceback # Para resolver los problemas que se tienen mienstras se escribe el código\n",
        "\n",
        "# DataFrame para llevar las cuentas de los archivos movidos.\n",
        "df_results = pd.DataFrame({\n",
        "    'us_number':[],\n",
        "    'apendicitis':[],\n",
        "    'no_apendicitis':[],\n",
        "    'no_apendice':[],\n",
        "    'no_class':[],\n",
        "    'no_id':[]\n",
        "})\n",
        "\n",
        "# Ruta a la carpeta donde están las imágenes sin ordenar\n",
        "folder_path = '/content/drive/MyDrive/Materias/Monografía/Tercera entrega - 03 Noviembre/datasets/dataset_filtrado/app_visible'\n",
        "\n",
        "# Rutas a las carpetas 'Mayor' y 'Menor'\n",
        "apendicitis = '/content/drive/MyDrive/Materias/Monografía/Tercera entrega - 03 Noviembre/datasets/dataset_ordenado/apendicitis'\n",
        "no_apendicitis = '/content/drive/MyDrive/Materias/Monografía/Tercera entrega - 03 Noviembre/datasets/dataset_ordenado/no_apendicitis'\n",
        "no_apendice = '/content/drive/MyDrive/Materias/Monografía/Tercera entrega - 03 Noviembre/datasets/dataset_ordenado/no_apendice'\n",
        "no_classification = '/content/drive/MyDrive/Materias/Monografía/Tercera entrega - 03 Noviembre/datasets/dataset_ordenado/no_classification'\n",
        "no_id = '/content/drive/MyDrive/Materias/Monografía/Tercera entrega - 03 Noviembre/datasets/dataset_ordenado/no_ID'\n",
        "\n",
        "# Función para extraer el número del nombre del archivo con ayuda\n",
        "# de las funciones regulares\n",
        "def extract_number(filename):\n",
        "    match = re.match(r\"(\\d+)\", filename)\n",
        "    return int(match.group(1)) if match else None\n",
        "\n",
        "# Procesar cada archivo en la carpeta\n",
        "count = 0 # Para poder almacenar los resultados en df_results\n",
        "for filename in os.listdir(folder_path):\n",
        "    # Revisión que el archivo si corresponda a una imagen\n",
        "    if filename.lower().endswith(('.png', '.bmp', '.jpeg', '.jpg', '.tif')):\n",
        "        number = extract_number(filename) # número entero del archivo\n",
        "\n",
        "        # Se busca en la base de datos filtrada si el número existe y se guardan\n",
        "        # todos los valores de su fila\n",
        "        fila_correspondiente = df_filtered.loc[df_filtered['US_Number'] == number]\n",
        "\n",
        "        try:\n",
        "            # Verifica que el número y la lista si existan\n",
        "            if number is not None and fila_correspondiente.empty != True:\n",
        "                df_results.loc[count, 'us_number'] = number\n",
        "\n",
        "                # Revisa si el apendice aparece en la imagen\n",
        "                if fila_correspondiente['Appendix_on_US'].iloc[0] == 'yes':\n",
        "\n",
        "                    # Revisa si el diagnóstico es appendicitis o sin esta\n",
        "                    if fila_correspondiente['Diagnosis'].iloc[0] == 'appendicitis':\n",
        "                        target_folder = apendicitis\n",
        "                        df_results.loc[count, 'apendicitis'] = 1\n",
        "                        df_results.loc[count, ['no_apendicitis',\n",
        "                                               'no_apendice',\n",
        "                                               'no_id']] = 0\n",
        "\n",
        "                    elif fila_correspondiente['Diagnosis'].iloc[0] == 'no_appendicitis':\n",
        "                        target_folder = no_apendicitis\n",
        "                        df_results.loc[count, 'no_apendicitis'] = 1\n",
        "                        df_results.loc[count, ['apendicitis',\n",
        "                                               'no_apendice',\n",
        "                                               'no_id']] = 0\n",
        "\n",
        "                    else:\n",
        "                        target_folder = no_classification\n",
        "                        df_results.loc[count, 'no_apendice'] = 1\n",
        "                        df_results.loc[count, ['no_apendicitis',\n",
        "                                               'apendicitis',\n",
        "                                               'no_id']] = 0\n",
        "\n",
        "                else:\n",
        "                    target_folder = no_apendice\n",
        "                    df_results.loc[count, 'no_apendice'] = 1\n",
        "                    df_results.loc[count, ['no_apendicitis',\n",
        "                                           'apendicitis',\n",
        "                                           'no_id']] = 0\n",
        "\n",
        "            # Imágenes cuyos pacientes NO existen en la base de datos\n",
        "            else:\n",
        "                target_folder = no_id\n",
        "                df_results.loc[count, 'no_id'] = 1\n",
        "                df_results.loc[count, ['no_apendicitis',\n",
        "                                       'apendicitis',\n",
        "                                       'no_apendice']] = 0\n",
        "\n",
        "            # Determinar la carpeta de destino y mover el archivo\n",
        "            #shutil.move(os.path.join(folder_path, filename),\n",
        "                            #os.path.join(target_folder, filename))\n",
        "\n",
        "        except Exception as e:\n",
        "            # Si hay un error, imprimirlo y continuar con la siguiente imagen\n",
        "            print(f\"No se pudo procesar el archivo: {filename}: {e}\")\n",
        "            traceback.print_exc() # Imprime el tipo de error\n",
        "\n",
        "    count += 1"
      ],
      "metadata": {
        "id": "ANFUhGFCCxan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imágenes que podría usar para no_apendicitis"
      ],
      "metadata": {
        "id": "n3ruurz6symR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imágenes donde se ve el apéndice y NO tiene apendicitis\n",
        "\n",
        "df_filtered2 = df_filtered[df_filtered['Appendix_on_US'] == 'yes']\n",
        "\n",
        "df_filtered2 = df_filtered2[df_filtered2['Diagnosis'] == 'no appendicitis']\n",
        "\n",
        "df_filtered2.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saU-ny6Vs5zT",
        "outputId": "0bfb02e5-b5fb-4ad9-dedc-1e5c5c507983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Appendix_on_US    126\n",
              "US_Number         125\n",
              "Diagnosis         126\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imágenes donde se ve el apéndice y tiene apendicitis\n",
        "\n",
        "df_filtered2 = df_filtered[df_filtered['Appendix_on_US'] == 'yes']\n",
        "\n",
        "df_filtered2 = df_filtered2[df_filtered2['Diagnosis'] == 'appendicitis']\n",
        "\n",
        "df_filtered2.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoP0EgS4tybl",
        "outputId": "8394939e-a378-4cad-ca8f-ec85d6d53541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Appendix_on_US    378\n",
              "US_Number         368\n",
              "Diagnosis         378\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imágenes donde se ve el apéndice y tiene apendicitis\n",
        "\n",
        "df_filtered2 = df_filtered[df_filtered['Appendix_on_US'] == 'no']\n",
        "\n",
        "df_filtered2.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRGvWCvgt8GZ",
        "outputId": "ad175963-9ad4-469f-bc40-8979bb2d61e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Appendix_on_US    273\n",
              "US_Number         263\n",
              "Diagnosis         273\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Referencias\n",
        "\n",
        "-\n",
        "-"
      ],
      "metadata": {
        "id": "yo3oBdt7byks"
      }
    }
  ]
}